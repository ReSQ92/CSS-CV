{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReSQ92/CSS-CV/blob/master/Image_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbvntCDQEMtW",
        "outputId": "7a9b11d8-a96f-4014-dfef-b7d98b17b431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.12.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dMq4tPBETSR",
        "outputId": "bf616d6f-ad3a-4b3d-db55-f5c688694646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU  grpc://10.123.131.58:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.123.131.58:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REPLICAS:  8\n"
          ]
        }
      ],
      "source": [
        "# @title Default title text\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ikBjfYU68BgX"
      },
      "outputs": [],
      "source": [
        "GCS_DS_PATH = 'gs://kds-163f79a0b36229ddbdee82c71aa129d3ea537863c839f4dd9fcf46e2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8WmUicSGJ__D"
      },
      "outputs": [],
      "source": [
        "import math, re, os\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iNalX97CHige"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = [192, 192] # at this size, a GPU will run out of memory. Use the TPU\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
        "\n",
        "NUM_TRAINING_IMAGES = 12753\n",
        "NUM_TEST_IMAGES = 7382\n",
        "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KK1HYz8GMoHZ"
      },
      "outputs": [],
      "source": [
        "def decode_image(image_data):\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
        "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n",
        "    return image\n",
        "\n",
        "def read_labeled_tfrecord(example):\n",
        "    LABELED_TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
        "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
        "    image = decode_image(example['image'])\n",
        "    label = tf.cast(example['class'], tf.int32)\n",
        "    return image, label # returns a dataset of (image, label) pairs\n",
        "\n",
        "def read_unlabeled_tfrecord(example):\n",
        "    UNLABELED_TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
        "        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n",
        "        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
        "    image = decode_image(example['image'])\n",
        "    idnum = example['id']\n",
        "    return image, idnum # returns a dataset of image(s)\n",
        "\n",
        "def load_dataset(filenames, labeled=True, ordered=False):\n",
        "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
        "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
        "\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(filenames) # automatically interleaves reads from multiple files\n",
        "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord)\n",
        "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
        "    return dataset\n",
        "\n",
        "def get_training_dataset():\n",
        "    dataset = load_dataset(tf.io.gfile.glob(GCS_DS_PATH + '/tfrecords-jpeg-192x192/train/*.tfrec'), labeled=True)\n",
        "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    return dataset\n",
        "\n",
        "def get_validation_dataset():\n",
        "    dataset = load_dataset(tf.io.gfile.glob(GCS_DS_PATH + '/tfrecords-jpeg-192x192/val/*.tfrec'), labeled=True, ordered=False)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.cache()\n",
        "    return dataset\n",
        "\n",
        "def get_test_dataset(ordered=False):\n",
        "    dataset = load_dataset(tf.io.gfile.glob(GCS_DS_PATH + '/tfrecords-jpeg-192x192/test/*.tfrec'), labeled=False, ordered=ordered)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    return dataset\n",
        "\n",
        "training_dataset = get_training_dataset()\n",
        "validation_dataset = get_validation_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twtaSb2kNCzo",
        "outputId": "c0903d7e-7c49-4616-ca5d-3f58ce2bf875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "99/99 [==============================] - 35s 217ms/step - loss: 4.0419 - sparse_categorical_accuracy: 0.1068 - val_loss: 3.7220 - val_sparse_categorical_accuracy: 0.1727\n",
            "Epoch 2/5\n",
            "99/99 [==============================] - 9s 95ms/step - loss: 3.5365 - sparse_categorical_accuracy: 0.2006 - val_loss: 3.3758 - val_sparse_categorical_accuracy: 0.2328\n",
            "Epoch 3/5\n",
            "99/99 [==============================] - 9s 96ms/step - loss: 3.2203 - sparse_categorical_accuracy: 0.2658 - val_loss: 3.1207 - val_sparse_categorical_accuracy: 0.2942\n",
            "Epoch 4/5\n",
            "99/99 [==============================] - 9s 89ms/step - loss: 2.9921 - sparse_categorical_accuracy: 0.3135 - val_loss: 2.9266 - val_sparse_categorical_accuracy: 0.3335\n",
            "Epoch 5/5\n",
            "99/99 [==============================] - 10s 97ms/step - loss: 2.7896 - sparse_categorical_accuracy: 0.3683 - val_loss: 2.7674 - val_sparse_categorical_accuracy: 0.3728\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
        "    pretrained_model.trainable = False # tramsfer learning\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        pretrained_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(104, activation='softmax')\n",
        "    ])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")\n",
        "\n",
        "historical = model.fit(training_dataset,\n",
        "          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "          epochs=EPOCHS,\n",
        "          validation_data=validation_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XXKW-qQLNGSX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4eee55f-f06a-408c-910b-8fd1d2e45f5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 7s 77ms/step - loss: 2.7674 - sparse_categorical_accuracy: 0.3728\n",
            "Validation Accuracy: 0.3728448152542114\n"
          ]
        }
      ],
      "source": [
        "validation_accuracy = model.evaluate(validation_dataset)[1]\n",
        "print(\"Validation Accuracy:\", validation_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ofq2YnRKY3Ex"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjWw6JsczXmyXQYzwOVMRU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}